{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4832512c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-04T15:55:26.989551Z",
     "iopub.status.busy": "2025-12-04T15:55:26.988701Z",
     "iopub.status.idle": "2025-12-04T15:55:28.787136Z",
     "shell.execute_reply": "2025-12-04T15:55:28.785962Z"
    },
    "papermill": {
     "duration": 1.805272,
     "end_time": "2025-12-04T15:55:28.788742",
     "exception": false,
     "start_time": "2025-12-04T15:55:26.983470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/prediction-with-goa-uniprot-all/ids_test.txt\n",
      "/kaggle/input/prediction-with-goa-uniprot-all/submission.tsv\n",
      "/kaggle/input/prediction-with-goa-uniprot-all/__results__.html\n",
      "/kaggle/input/prediction-with-goa-uniprot-all/__notebook__.ipynb\n",
      "/kaggle/input/prediction-with-goa-uniprot-all/__output__.json\n",
      "/kaggle/input/prediction-with-goa-uniprot-all/custom.css\n",
      "/kaggle/input/k/daovanda2405/cafa-6-protein-function-starter-eda-model/submission.tsv\n",
      "/kaggle/input/k/daovanda2405/cafa-6-protein-function-starter-eda-model/__results__.html\n",
      "/kaggle/input/k/daovanda2405/cafa-6-protein-function-starter-eda-model/__notebook__.ipynb\n",
      "/kaggle/input/k/daovanda2405/cafa-6-protein-function-starter-eda-model/__output__.json\n",
      "/kaggle/input/k/daovanda2405/cafa-6-protein-function-starter-eda-model/custom.css\n",
      "/kaggle/input/k/daovanda2405/cafa-6-protein-function-starter-eda-model/__results___files/__results___1_3.png\n",
      "/kaggle/input/k/daovanda2405/cafa-6-protein-function-starter-eda-model/__results___files/__results___1_5.png\n",
      "/kaggle/input/k/daovanda2405/cafa-6-protein-function-starter-eda-model/__results___files/__results___1_1.png\n",
      "/kaggle/input/cafa-6-protein-function-starter-eda-model/submission.tsv\n",
      "/kaggle/input/cafa-6-protein-function-starter-eda-model/__results__.html\n",
      "/kaggle/input/cafa-6-protein-function-starter-eda-model/__notebook__.ipynb\n",
      "/kaggle/input/cafa-6-protein-function-starter-eda-model/__output__.json\n",
      "/kaggle/input/cafa-6-protein-function-starter-eda-model/custom.css\n",
      "/kaggle/input/cafa-6-protein-function-starter-eda-model/__results___files/__results___1_3.png\n",
      "/kaggle/input/cafa-6-protein-function-starter-eda-model/__results___files/__results___1_5.png\n",
      "/kaggle/input/cafa-6-protein-function-starter-eda-model/__results___files/__results___1_1.png\n",
      "/kaggle/input/cafa-6-protein-function-prediction/sample_submission.tsv\n",
      "/kaggle/input/cafa-6-protein-function-prediction/IA.tsv\n",
      "/kaggle/input/cafa-6-protein-function-prediction/Test/testsuperset.fasta\n",
      "/kaggle/input/cafa-6-protein-function-prediction/Test/testsuperset-taxon-list.tsv\n",
      "/kaggle/input/cafa-6-protein-function-prediction/Train/train_terms.tsv\n",
      "/kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta\n",
      "/kaggle/input/cafa-6-protein-function-prediction/Train/train_taxonomy.tsv\n",
      "/kaggle/input/cafa-6-protein-function-prediction/Train/go-basic.obo\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee6aeea4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T15:55:28.795539Z",
     "iopub.status.busy": "2025-12-04T15:55:28.795019Z",
     "iopub.status.idle": "2025-12-04T16:25:18.885750Z",
     "shell.execute_reply": "2025-12-04T16:25:18.884708Z"
    },
    "papermill": {
     "duration": 1790.101164,
     "end_time": "2025-12-04T16:25:18.892463",
     "exception": false,
     "start_time": "2025-12-04T15:55:28.791299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MULTI-MODEL ENSEMBLE FOR PROTEIN FUNCTION PREDICTION\n",
      "============================================================\n",
      "\n",
      "‚öôÔ∏è Configuration:\n",
      "  - Model A weight: 0.60\n",
      "  - Model B weight: 0.20\n",
      "  - Model C weight: 0.20\n",
      "  - Diversity bonus: adaptive\n",
      "  - Min score for bonus: 0.01\n",
      "  - Score calibration: False\n",
      "  - Confidence threshold: 0.01\n",
      "  - Top-K per protein: 1500\n",
      "\n",
      "üìÇ Loading Model A (GOA-UniProt)...\n",
      "  ‚úì Loaded 51,391,680 predictions\n",
      "  ‚úì Unique proteins: 279,437\n",
      "  ‚úì Unique GO terms: 32,618\n",
      "  ‚úì Score range: [0.0100, 1.0000]\n",
      "  ‚úì Mean score: 0.2410\n",
      "  ‚ö†Ô∏è Removing 2,513,060 duplicates...\n",
      "  ‚è±Ô∏è Loading time: 201.72s\n",
      "  üíæ Memory usage: ~10.76 GB\n",
      "\n",
      "üìÇ Loading Model B (Starter EDA)...\n",
      "  ‚úì Loaded 14,037,195 predictions\n",
      "  ‚úì Unique proteins: 202,893\n",
      "  ‚úì Unique GO terms: 31,451\n",
      "  ‚úì Score range: [0.0102, 1.0000]\n",
      "  ‚úì Mean score: 0.2772\n",
      "  ‚è±Ô∏è Loading time: 30.52s\n",
      "  üíæ Memory usage: ~2.98 GB\n",
      "\n",
      "üìÇ Loading Model C (Custom Model)...\n",
      "  ‚úì Loaded 46,564,288 predictions\n",
      "  ‚úì Unique proteins: 141,864\n",
      "  ‚úì Unique GO terms: 2,200\n",
      "  ‚úì Score range: [0.0100, 0.9990]\n",
      "  ‚úì Mean score: 0.0528\n",
      "  ‚è±Ô∏è Loading time: 92.39s\n",
      "  üíæ Memory usage: ~9.87 GB\n",
      "\n",
      "üî® Analyzing overlap...\n",
      "  ‚úì Total unique predictions: 88,481,206\n",
      "  ‚úì Only in Model A: 33,164,724 (37.5%)\n",
      "  ‚úì Only in Model B: 29,951 (0.0%)\n",
      "  ‚úì Only in Model C: 38,411,427 (43.4%)\n",
      "  ‚úì Overlap A‚à©B: 12,846,036 (14.5%)\n",
      "  ‚úì Overlap A‚à©C: 6,991,653 (7.9%)\n",
      "  ‚úì Overlap B‚à©C: 5,285,001 (6.0%)\n",
      "  ‚úì Overlap A‚à©B‚à©C: 4,123,793 (4.7%)\n",
      "  ‚úì Overlap (A‚à©B‚à©C) avg score A: 0.4385\n",
      "  ‚úì Overlap (A‚à©B‚à©C) avg score B: 0.2706\n",
      "  ‚úì Overlap (A‚à©B‚à©C) avg score C: 0.2908\n",
      "\n",
      "üöÄ Creating ensemble (memory-efficient method)...\n",
      "  üìä Merging models...\n",
      "  ‚úì Merged: 88,481,206 total predictions\n",
      "  üíæ Memory usage: ~17.57 GB\n",
      "  üîç Early filtering to reduce memory...\n",
      "    ‚úì Kept 88,481,206/88,481,206 predictions (100.0%)\n",
      "    ‚úì Freed ~0.00 GB\n",
      "    üíæ Current memory: ~17.57 GB\n",
      "  üßÆ Calculating ensemble scores (mode: adaptive)...\n",
      "  üéÅ Applying diversity bonus...\n",
      "    ‚ÑπÔ∏è Computing bonus for 4,123,793 predictions...\n",
      "    ‚úì Bonus applied to 4,123,793 predictions (4.7%)\n",
      "  üíæ Memory after cleanup: ~9.60 GB\n",
      "  ‚úì Ensemble created in 948.28s\n",
      "\n",
      "üîç Filtering predictions...\n",
      "  - Before final filter: 88,481,206 predictions\n",
      "  - After confidence filter (‚â•0.01): 50,209,244 predictions (removed 38,271,962)\n",
      "  - Applying top-1500 per protein filter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/indexing.py:223: RuntimeWarning: invalid value encountered in less\n",
      "  mask &= self._ascending_count < stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - After top-K filter: 46,190,852 predictions\n",
      "\n",
      "üìä Final Statistics:\n",
      "  - Total predictions: 46,190,852\n",
      "  - Proteins covered: 279,437\n",
      "  - GO terms covered: 32,618\n",
      "  - Avg predictions per protein: 165.3\n",
      "  - Score distribution:\n",
      "    ‚Ä¢ Mean: 0.1557\n",
      "    ‚Ä¢ Median: 0.0552\n",
      "    ‚Ä¢ Std: 0.2118\n",
      "    ‚Ä¢ Min: 0.0100\n",
      "    ‚Ä¢ Max: 1.0000\n",
      "\n",
      "üíæ Saving submission...\n",
      "  ‚úì Saved to: submission.tsv\n",
      "\n",
      "‚è±Ô∏è Total execution time: 1789.80s (29.8 minutes)\n",
      "============================================================\n",
      "‚úÖ ENSEMBLE COMPLETE!\n",
      "üéØ Experiment with different parameters to optimize score!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import gc\n",
    "\n",
    "# ==================== CONFIGURATION ====================\n",
    "print(\"=\"*60)\n",
    "print(\"MULTI-MODEL ENSEMBLE FOR PROTEIN FUNCTION PREDICTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============ TUNING SECTION - EXPERIMENT WITH THESE ============\n",
    "\n",
    "# Strategy 1: Model weights (MUST SUM TO 1.0)\n",
    "WEIGHT_MODEL_A = 0.60  \n",
    "WEIGHT_MODEL_B = 0.20  \n",
    "WEIGHT_MODEL_C = 0.20 \n",
    "\n",
    "# Validate weights\n",
    "assert abs(WEIGHT_MODEL_A + WEIGHT_MODEL_B + WEIGHT_MODEL_C - 1.0) < 0.001, \"Weights must sum to 1.0!\"\n",
    "\n",
    "# Strategy 2: Diversity bonus \n",
    "DIVERSITY_BONUS_MODE = 'adaptive'  # 'fixed', 'adaptive', 'multiplicative', or 'none'\n",
    "DIVERSITY_BONUS_FIXED = 0.05\n",
    "DIVERSITY_BONUS_MIN = 0.02\n",
    "DIVERSITY_BONUS_MAX = 0.08  \n",
    "MIN_SCORE_FOR_BONUS = 0.01  # Match v·ªõi CONFIDENCE_THRESHOLD ƒë·ªÉ kh√¥ng b·ªè s√≥t\n",
    "\n",
    "# Strategy 3: Score calibration\n",
    "APPLY_SCORE_CALIBRATION = False\n",
    "CALIBRATION_POWER_A = 1.0\n",
    "CALIBRATION_POWER_B = 1.0\n",
    "CALIBRATION_POWER_C = 1.0\n",
    "\n",
    "# Strategy 4: Filtering thresholds\n",
    "CONFIDENCE_THRESHOLD = 0.01  # Gi·ªØ th·∫•p cho Fmax\n",
    "TOP_K_PER_PROTEIN = 1500\n",
    "\n",
    "# Strategy 5: Conflict resolution\n",
    "CONFLICT_RESOLUTION = 'weighted'  # 'weighted', 'max', 'min'\n",
    "\n",
    "# ================================================================\n",
    "\n",
    "# Memory optimization (KH√îNG THAY ƒê·ªîI)\n",
    "BATCH_SIZE = 1_000_000\n",
    "EARLY_FILTER = True  # B·∫¨T early filter ƒë·ªÉ gi·∫£m RAM\n",
    "MIN_SCORE_TO_KEEP = 0.01  # L·ªçc s·ªõm predictions qu√° th·∫•p\n",
    "SCORE_CLIP_MIN = 0.0\n",
    "SCORE_CLIP_MAX = 1.0\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è Configuration:\")\n",
    "print(f\"  - Model A weight: {WEIGHT_MODEL_A:.2f}\")\n",
    "print(f\"  - Model B weight: {WEIGHT_MODEL_B:.2f}\")\n",
    "print(f\"  - Model C weight: {WEIGHT_MODEL_C:.2f}\")\n",
    "print(f\"  - Diversity bonus: {DIVERSITY_BONUS_MODE}\")\n",
    "print(f\"  - Min score for bonus: {MIN_SCORE_FOR_BONUS}\")\n",
    "print(f\"  - Score calibration: {APPLY_SCORE_CALIBRATION}\")\n",
    "print(f\"  - Confidence threshold: {CONFIDENCE_THRESHOLD}\")\n",
    "print(f\"  - Top-K per protein: {TOP_K_PER_PROTEIN}\")\n",
    "\n",
    "# ==================== HELPER FUNCTIONS ====================\n",
    "\n",
    "def load_model_with_validation(filepath, model_name, calibration_power=1.0):\n",
    "    \"\"\"Load v√† validate model predictions v·ªõi memory optimization\"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"\\nüìÇ Loading {model_name}...\")\n",
    "    \n",
    "    chunks = []\n",
    "    chunk_size = 5_000_000\n",
    "    \n",
    "    for chunk in pd.read_csv(filepath, sep='\\t', header=None, \n",
    "                              names=['protein', 'go_term', 'score'],\n",
    "                              chunksize=chunk_size):\n",
    "        # Clip scores\n",
    "        chunk['score'] = chunk['score'].clip(SCORE_CLIP_MIN, SCORE_CLIP_MAX)\n",
    "        \n",
    "        # Score calibration\n",
    "        if APPLY_SCORE_CALIBRATION and calibration_power != 1.0:\n",
    "            chunk['score'] = np.power(chunk['score'], calibration_power)\n",
    "        \n",
    "        # Filter early n·∫øu b·∫≠t\n",
    "        if EARLY_FILTER:\n",
    "            chunk = chunk[chunk['score'] >= MIN_SCORE_TO_KEEP]\n",
    "        \n",
    "        chunk['key'] = chunk['protein'] + '|' + chunk['go_term']\n",
    "        chunks.append(chunk)\n",
    "    \n",
    "    df = pd.concat(chunks, ignore_index=True)\n",
    "    del chunks\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"  ‚úì Loaded {len(df):,} predictions\")\n",
    "    print(f\"  ‚úì Unique proteins: {df['protein'].nunique():,}\")\n",
    "    print(f\"  ‚úì Unique GO terms: {df['go_term'].nunique():,}\")\n",
    "    print(f\"  ‚úì Score range: [{df['score'].min():.4f}, {df['score'].max():.4f}]\")\n",
    "    print(f\"  ‚úì Mean score: {df['score'].mean():.4f}\")\n",
    "    \n",
    "    # Remove duplicates\n",
    "    duplicates = df['key'].duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        print(f\"  ‚ö†Ô∏è Removing {duplicates:,} duplicates...\")\n",
    "        df = df.sort_values('score', ascending=False).drop_duplicates('key', keep='first')\n",
    "        gc.collect()\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"  ‚è±Ô∏è Loading time: {elapsed:.2f}s\")\n",
    "    print(f\"  üíæ Memory usage: ~{df.memory_usage(deep=True).sum() / 1e9:.2f} GB\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calculate_adaptive_bonus(scores_list):\n",
    "    \"\"\"Bonus cao khi t·∫•t c·∫£ model T·ª∞ TIN v√† ƒê·ªíNG √ù (m·ªü r·ªông cho 3 models)\"\"\"\n",
    "    scores_array = np.array(scores_list).T  # shape: (n_predictions, n_models)\n",
    "    \n",
    "    # T√≠nh agreement: 1 - std c·ªßa scores\n",
    "    agreement = 1 - np.std(scores_array, axis=1) / (np.mean(scores_array, axis=1) + 1e-8)\n",
    "    agreement = np.clip(agreement, 0, 1)\n",
    "    \n",
    "    # T√≠nh average confidence\n",
    "    avg_confidence = np.mean(scores_array, axis=1)\n",
    "    \n",
    "    # Penalty n·∫øu c√≥ model n√†o qu√° th·∫•p\n",
    "    min_score = np.min(scores_array, axis=1)\n",
    "    confidence_factor = min_score / MIN_SCORE_FOR_BONUS if MIN_SCORE_FOR_BONUS > 0 else 1.0\n",
    "    confidence_factor = np.clip(confidence_factor, 0, 1)\n",
    "    \n",
    "    bonus = (DIVERSITY_BONUS_MIN + \n",
    "             (DIVERSITY_BONUS_MAX - DIVERSITY_BONUS_MIN) * agreement * avg_confidence)\n",
    "    \n",
    "    return bonus * confidence_factor\n",
    "\n",
    "def calculate_multiplicative_bonus(scores_list, weights):\n",
    "    \"\"\"Multiplicative ensemble - t·ªët khi t·∫•t c·∫£ model t·ª± tin (m·ªü r·ªông cho 3 models)\"\"\"\n",
    "    scores_array = np.array(scores_list).T  # shape: (n_predictions, n_models)\n",
    "    \n",
    "    # Geometric mean (nth root of product)\n",
    "    geometric_mean = np.prod(scores_array, axis=1) ** (1.0 / len(scores_list))\n",
    "    \n",
    "    # Weighted average\n",
    "    weighted_avg = np.dot(scores_array, weights)\n",
    "    \n",
    "    # Blend gi·ªØa weighted average v√† geometric mean\n",
    "    alpha = 0.2  # 20% geometric, 80% weighted\n",
    "    return alpha * geometric_mean + (1 - alpha) * weighted_avg\n",
    "\n",
    "# ==================== MAIN PIPELINE ====================\n",
    "\n",
    "overall_start = time.time()\n",
    "\n",
    "# Load all models\n",
    "model_a = load_model_with_validation(\n",
    "    '/kaggle/input/prediction-with-goa-uniprot-all/submission.tsv',\n",
    "    'Model A (GOA-UniProt)',\n",
    "    calibration_power=CALIBRATION_POWER_A\n",
    ")\n",
    "\n",
    "model_b = load_model_with_validation(\n",
    "    '/kaggle/input/cafa-6-protein-function-starter-eda-model/submission.tsv',\n",
    "    'Model B (Starter EDA)',\n",
    "    calibration_power=CALIBRATION_POWER_B\n",
    ")\n",
    "\n",
    "model_c = load_model_with_validation(\n",
    "    '/kaggle/input/k/daovanda2405/cafa-6-protein-function-starter-eda-model/submission.tsv',\n",
    "    'Model C (Custom Model)',\n",
    "    calibration_power=CALIBRATION_POWER_C\n",
    ")\n",
    "\n",
    "# Analyze overlap\n",
    "print(f\"\\nüî® Analyzing overlap...\")\n",
    "keys_a = set(model_a['key'])\n",
    "keys_b = set(model_b['key'])\n",
    "keys_c = set(model_c['key'])\n",
    "\n",
    "all_keys = keys_a | keys_b | keys_c\n",
    "overlap_ab = keys_a & keys_b\n",
    "overlap_ac = keys_a & keys_c\n",
    "overlap_bc = keys_b & keys_c\n",
    "overlap_abc = keys_a & keys_b & keys_c\n",
    "\n",
    "only_a = len(keys_a - keys_b - keys_c)\n",
    "only_b = len(keys_b - keys_a - keys_c)\n",
    "only_c = len(keys_c - keys_a - keys_b)\n",
    "\n",
    "print(f\"  ‚úì Total unique predictions: {len(all_keys):,}\")\n",
    "print(f\"  ‚úì Only in Model A: {only_a:,} ({only_a/len(all_keys)*100:.1f}%)\")\n",
    "print(f\"  ‚úì Only in Model B: {only_b:,} ({only_b/len(all_keys)*100:.1f}%)\")\n",
    "print(f\"  ‚úì Only in Model C: {only_c:,} ({only_c/len(all_keys)*100:.1f}%)\")\n",
    "print(f\"  ‚úì Overlap A‚à©B: {len(overlap_ab):,} ({len(overlap_ab)/len(all_keys)*100:.1f}%)\")\n",
    "print(f\"  ‚úì Overlap A‚à©C: {len(overlap_ac):,} ({len(overlap_ac)/len(all_keys)*100:.1f}%)\")\n",
    "print(f\"  ‚úì Overlap B‚à©C: {len(overlap_bc):,} ({len(overlap_bc)/len(all_keys)*100:.1f}%)\")\n",
    "print(f\"  ‚úì Overlap A‚à©B‚à©C: {len(overlap_abc):,} ({len(overlap_abc)/len(all_keys)*100:.1f}%)\")\n",
    "\n",
    "# Calculate overlap score statistics\n",
    "if len(overlap_abc) > 0:\n",
    "    overlap_a_scores = model_a[model_a['key'].isin(overlap_abc)]['score']\n",
    "    overlap_b_scores = model_b[model_b['key'].isin(overlap_abc)]['score']\n",
    "    overlap_c_scores = model_c[model_c['key'].isin(overlap_abc)]['score']\n",
    "    print(f\"  ‚úì Overlap (A‚à©B‚à©C) avg score A: {overlap_a_scores.mean():.4f}\")\n",
    "    print(f\"  ‚úì Overlap (A‚à©B‚à©C) avg score B: {overlap_b_scores.mean():.4f}\")\n",
    "    print(f\"  ‚úì Overlap (A‚à©B‚à©C) avg score C: {overlap_c_scores.mean():.4f}\")\n",
    "\n",
    "del keys_a, keys_b, keys_c, all_keys, overlap_ab, overlap_ac, overlap_bc, overlap_abc\n",
    "gc.collect()\n",
    "\n",
    "# Merge strategy\n",
    "print(f\"\\nüöÄ Creating ensemble (memory-efficient method)...\")\n",
    "start_time = time.time()\n",
    "\n",
    "model_a_clean = model_a[['key', 'protein', 'go_term', 'score']].rename(columns={'score': 'score_a'})\n",
    "model_b_clean = model_b[['key', 'score']].rename(columns={'score': 'score_b'})\n",
    "model_c_clean = model_c[['key', 'score']].rename(columns={'score': 'score_c'})\n",
    "\n",
    "del model_a, model_b, model_c\n",
    "gc.collect()\n",
    "\n",
    "print(f\"  üìä Merging models...\")\n",
    "# Merge A and B first\n",
    "ensemble = model_a_clean.merge(model_b_clean, on='key', how='outer')\n",
    "del model_b_clean\n",
    "gc.collect()\n",
    "\n",
    "# Then merge with C\n",
    "ensemble = ensemble.merge(model_c_clean, on='key', how='outer')\n",
    "del model_a_clean, model_c_clean\n",
    "gc.collect()\n",
    "\n",
    "# Fill NaN\n",
    "ensemble['score_a'] = ensemble['score_a'].fillna(0)\n",
    "ensemble['score_b'] = ensemble['score_b'].fillna(0)\n",
    "ensemble['score_c'] = ensemble['score_c'].fillna(0)\n",
    "\n",
    "# Free memory immediately\n",
    "gc.collect()\n",
    "\n",
    "print(f\"  ‚úì Merged: {len(ensemble):,} total predictions\")\n",
    "print(f\"  üíæ Memory usage: ~{ensemble.memory_usage(deep=True).sum() / 1e9:.2f} GB\")\n",
    "\n",
    "# FILTER EARLY ƒë·ªÉ gi·∫£m data tr∆∞·ªõc khi t√≠nh to√°n ph·ª©c t·∫°p\n",
    "print(f\"  üîç Early filtering to reduce memory...\")\n",
    "initial_count = len(ensemble)\n",
    "\n",
    "# Ch·ªâ gi·ªØ predictions c√≥ √≠t nh·∫•t 1 model score > threshold\n",
    "mask_keep = (ensemble['score_a'] >= MIN_SCORE_TO_KEEP) | \\\n",
    "            (ensemble['score_b'] >= MIN_SCORE_TO_KEEP) | \\\n",
    "            (ensemble['score_c'] >= MIN_SCORE_TO_KEEP)\n",
    "\n",
    "ensemble = ensemble[mask_keep].copy()\n",
    "del mask_keep\n",
    "gc.collect()\n",
    "\n",
    "filtered_count = len(ensemble)\n",
    "print(f\"    ‚úì Kept {filtered_count:,}/{initial_count:,} predictions ({filtered_count/initial_count*100:.1f}%)\")\n",
    "print(f\"    ‚úì Freed ~{(initial_count - filtered_count) * 200 / 1e9:.2f} GB\")\n",
    "print(f\"    üíæ Current memory: ~{ensemble.memory_usage(deep=True).sum() / 1e9:.2f} GB\")\n",
    "\n",
    "# Calculate base ensemble score\n",
    "print(f\"  üßÆ Calculating ensemble scores (mode: {DIVERSITY_BONUS_MODE})...\")\n",
    "\n",
    "if DIVERSITY_BONUS_MODE == 'multiplicative':\n",
    "    # Multiplicative ensemble\n",
    "    mask_all = (ensemble['score_a'] > 0) & (ensemble['score_b'] > 0) & (ensemble['score_c'] > 0)\n",
    "    \n",
    "    # Base weighted average\n",
    "    ensemble['score'] = (ensemble['score_a'] * WEIGHT_MODEL_A + \n",
    "                        ensemble['score_b'] * WEIGHT_MODEL_B + \n",
    "                        ensemble['score_c'] * WEIGHT_MODEL_C)\n",
    "    \n",
    "    if mask_all.sum() > 0:\n",
    "        weights = np.array([WEIGHT_MODEL_A, WEIGHT_MODEL_B, WEIGHT_MODEL_C])\n",
    "        scores_list = [\n",
    "            ensemble.loc[mask_all, 'score_a'].values,\n",
    "            ensemble.loc[mask_all, 'score_b'].values,\n",
    "            ensemble.loc[mask_all, 'score_c'].values\n",
    "        ]\n",
    "        ensemble.loc[mask_all, 'score'] = calculate_multiplicative_bonus(scores_list, weights)\n",
    "        print(f\"    ‚úì Multiplicative bonus applied to {mask_all.sum():,} predictions\")\n",
    "    \n",
    "    ensemble['bonus'] = 0.0\n",
    "    \n",
    "else:\n",
    "    # Weighted average base\n",
    "    ensemble['weighted_score'] = (\n",
    "        ensemble['score_a'] * WEIGHT_MODEL_A + \n",
    "        ensemble['score_b'] * WEIGHT_MODEL_B +\n",
    "        ensemble['score_c'] * WEIGHT_MODEL_C\n",
    "    )\n",
    "    \n",
    "    # Apply diversity bonus\n",
    "    print(f\"  üéÅ Applying diversity bonus...\")\n",
    "    if DIVERSITY_BONUS_MODE == 'adaptive':\n",
    "        # Apply bonus cho t·∫•t c·∫£ predictions c√≥ c·∫£ 3 models predict (kh√¥ng c·∫ßn threshold cao)\n",
    "        mask_all = ((ensemble['score_a'] >= MIN_SCORE_FOR_BONUS) & \n",
    "                    (ensemble['score_b'] >= MIN_SCORE_FOR_BONUS) & \n",
    "                    (ensemble['score_c'] >= MIN_SCORE_FOR_BONUS))\n",
    "        \n",
    "        ensemble['bonus'] = 0.0\n",
    "        n_bonus = mask_all.sum()\n",
    "        \n",
    "        if n_bonus > 0:\n",
    "            print(f\"    ‚ÑπÔ∏è Computing bonus for {n_bonus:,} predictions...\")\n",
    "            \n",
    "            # X·ª≠ l√Ω theo BATCH ƒë·ªÉ tr√°nh tr√†n RAM\n",
    "            batch_size = 5_000_000\n",
    "            if n_bonus > batch_size:\n",
    "                print(f\"    ‚ÑπÔ∏è Processing in batches of {batch_size:,}...\")\n",
    "                indices = ensemble.index[mask_all].tolist()\n",
    "                \n",
    "                for i in range(0, len(indices), batch_size):\n",
    "                    batch_idx = indices[i:i+batch_size]\n",
    "                    scores_list = [\n",
    "                        ensemble.loc[batch_idx, 'score_a'].values,\n",
    "                        ensemble.loc[batch_idx, 'score_b'].values,\n",
    "                        ensemble.loc[batch_idx, 'score_c'].values\n",
    "                    ]\n",
    "                    ensemble.loc[batch_idx, 'bonus'] = calculate_adaptive_bonus(scores_list)\n",
    "                    \n",
    "                    if i % (batch_size * 5) == 0:\n",
    "                        print(f\"      Processed {i:,}/{n_bonus:,} predictions...\")\n",
    "                    \n",
    "                    del scores_list, batch_idx\n",
    "                    gc.collect()\n",
    "            else:\n",
    "                scores_list = [\n",
    "                    ensemble.loc[mask_all, 'score_a'].values,\n",
    "                    ensemble.loc[mask_all, 'score_b'].values,\n",
    "                    ensemble.loc[mask_all, 'score_c'].values\n",
    "                ]\n",
    "                ensemble.loc[mask_all, 'bonus'] = calculate_adaptive_bonus(scores_list)\n",
    "                del scores_list\n",
    "                gc.collect()\n",
    "            \n",
    "            print(f\"    ‚úì Bonus applied to {n_bonus:,} predictions ({n_bonus/len(ensemble)*100:.1f}%)\")\n",
    "            del mask_all\n",
    "            gc.collect()\n",
    "        else:\n",
    "            print(f\"    ‚ö†Ô∏è No predictions meet bonus criteria (MIN_SCORE_FOR_BONUS={MIN_SCORE_FOR_BONUS})\")\n",
    "    \n",
    "    elif DIVERSITY_BONUS_MODE == 'fixed':\n",
    "        mask_all = (ensemble['score_a'] > 0) & (ensemble['score_b'] > 0) & (ensemble['score_c'] > 0)\n",
    "        ensemble['bonus'] = 0.0\n",
    "        n_bonus = mask_all.sum()\n",
    "        ensemble.loc[mask_all, 'bonus'] = DIVERSITY_BONUS_FIXED\n",
    "        print(f\"    ‚úì Fixed bonus applied to {n_bonus:,} predictions ({n_bonus/len(ensemble)*100:.1f}%)\")\n",
    "        del mask_all\n",
    "        gc.collect()\n",
    "    \n",
    "    else:\n",
    "        ensemble['bonus'] = 0.0\n",
    "    \n",
    "    # Final score\n",
    "    ensemble['score'] = (ensemble['weighted_score'] + ensemble['bonus']).clip(upper=SCORE_CLIP_MAX)\n",
    "\n",
    "# Conflict resolution\n",
    "if CONFLICT_RESOLUTION == 'max':\n",
    "    # Take max of individual scores or ensemble\n",
    "    ensemble['score'] = ensemble[['score_a', 'score_b', 'score_c', 'score']].max(axis=1)\n",
    "elif CONFLICT_RESOLUTION == 'min':\n",
    "    # Conservative: take min where all predict\n",
    "    mask_all = (ensemble['score_a'] > 0) & (ensemble['score_b'] > 0) & (ensemble['score_c'] > 0)\n",
    "    ensemble.loc[mask_all, 'score'] = ensemble.loc[mask_all, ['score_a', 'score_b', 'score_c']].min(axis=1)\n",
    "\n",
    "# Drop intermediate columns ƒë·ªÉ gi·∫£m memory\n",
    "ensemble = ensemble[['protein', 'go_term', 'score']].copy()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"  üíæ Memory after cleanup: ~{ensemble.memory_usage(deep=True).sum() / 1e9:.2f} GB\")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"  ‚úì Ensemble created in {elapsed:.2f}s\")\n",
    "\n",
    "# Filtering\n",
    "print(f\"\\nüîç Filtering predictions...\")\n",
    "print(f\"  - Before final filter: {len(ensemble):,} predictions\")\n",
    "\n",
    "# Apply confidence threshold\n",
    "if CONFIDENCE_THRESHOLD > 0:\n",
    "    before = len(ensemble)\n",
    "    ensemble = ensemble[ensemble['score'] >= CONFIDENCE_THRESHOLD].copy()\n",
    "    gc.collect()\n",
    "    after = len(ensemble)\n",
    "    print(f\"  - After confidence filter (‚â•{CONFIDENCE_THRESHOLD}): {after:,} predictions (removed {before-after:,})\")\n",
    "else:\n",
    "    print(f\"  - No confidence threshold applied\")\n",
    "\n",
    "# Top-K per protein\n",
    "if TOP_K_PER_PROTEIN is not None:\n",
    "    print(f\"  - Applying top-{TOP_K_PER_PROTEIN} per protein filter...\")\n",
    "    ensemble = ensemble.sort_values('score', ascending=False)\n",
    "    ensemble = ensemble.groupby('protein').head(TOP_K_PER_PROTEIN).reset_index(drop=True)\n",
    "    gc.collect()\n",
    "    print(f\"  - After top-K filter: {len(ensemble):,} predictions\")\n",
    "\n",
    "# Sort by score\n",
    "ensemble = ensemble.sort_values('score', ascending=False)\n",
    "\n",
    "# Statistics\n",
    "print(f\"\\nüìä Final Statistics:\")\n",
    "print(f\"  - Total predictions: {len(ensemble):,}\")\n",
    "print(f\"  - Proteins covered: {ensemble['protein'].nunique():,}\")\n",
    "print(f\"  - GO terms covered: {ensemble['go_term'].nunique():,}\")\n",
    "print(f\"  - Avg predictions per protein: {len(ensemble)/ensemble['protein'].nunique():.1f}\")\n",
    "print(f\"  - Score distribution:\")\n",
    "print(f\"    ‚Ä¢ Mean: {ensemble['score'].mean():.4f}\")\n",
    "print(f\"    ‚Ä¢ Median: {ensemble['score'].median():.4f}\")\n",
    "print(f\"    ‚Ä¢ Std: {ensemble['score'].std():.4f}\")\n",
    "print(f\"    ‚Ä¢ Min: {ensemble['score'].min():.4f}\")\n",
    "print(f\"    ‚Ä¢ Max: {ensemble['score'].max():.4f}\")\n",
    "\n",
    "# Save submission\n",
    "print(f\"\\nüíæ Saving submission...\")\n",
    "output_file = 'submission.tsv'\n",
    "ensemble[['protein', 'go_term', 'score']].to_csv(\n",
    "    output_file, \n",
    "    sep='\\t', \n",
    "    index=False, \n",
    "    header=False\n",
    ")\n",
    "print(f\"  ‚úì Saved to: {output_file}\")\n",
    "\n",
    "# Total time\n",
    "total_time = time.time() - overall_start\n",
    "print(f\"\\n‚è±Ô∏è Total execution time: {total_time:.2f}s ({total_time/60:.1f} minutes)\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ ENSEMBLE COMPLETE!\")\n",
    "print(f\"üéØ Experiment with different parameters to optimize score!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14084779,
     "sourceId": 116062,
     "sourceType": "competition"
    },
    {
     "sourceId": 282364487,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 282897090,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 283250975,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1797.869486,
   "end_time": "2025-12-04T16:25:20.327764",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-04T15:55:22.458278",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
